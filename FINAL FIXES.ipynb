{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "335e5dbe-a4c5-4a65-94a0-c2d2738f2cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regenerated locations.csv with 38114 rows\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Load only the meteorite_id column from your cleaned landings:\n",
    "cleaned = pd.read_csv(\"cleaned_meteorite_landings.csv\", usecols=[\"meteorite_id\"])\n",
    "\n",
    "# 2. Load the raw lat/lon from the original:\n",
    "raw_loc = pd.read_csv(\n",
    "    \"Meteorite_Landings.csv\",\n",
    "    usecols=[\"id\", \"reclat\", \"reclong\"]\n",
    ").rename(columns={\n",
    "    \"id\": \"meteorite_id\",\n",
    "    \"reclat\": \"latitude\",\n",
    "    \"reclong\": \"longitude\"\n",
    "})\n",
    "\n",
    "# 3. Keep just those meteorite_ids that survived your cleaning:\n",
    "raw_loc = raw_loc[raw_loc[\"meteorite_id\"].isin(cleaned[\"meteorite_id\"])]\n",
    "\n",
    "# 4. Helper to bucket region/country\n",
    "def approx_region_country(lat, lon):\n",
    "    if 24.5 <= lat <= 49.0 and -125.0 <= lon <= -66.9: return \"North America\", \"USA\"\n",
    "    if -33.0 <= lat <= 5.0   and -74.0 <= lon <= -34.0: return \"South America\", \"Brazil\"\n",
    "    if 35.0 <= lat <= 71.0   and -10.0 <= lon <= 40.0:   return \"Europe\",        \"Germany\"\n",
    "    if -44.0 <= lat <= -10.0 and 112.0 <= lon <= 154.0:  return \"Oceania\",       \"Australia\"\n",
    "    if 20.0 <= lat <= 55.0   and 60.0 <= lon <= 100.0:   return \"Asia\",          \"China\"\n",
    "    if -35.0 <= lat <= 37.0  and -17.0 <= lon <= 51.0:   return \"Africa\",        \"Egypt\"\n",
    "    if lat > 70:    return \"Arctic\",      \"Arctic Region\"\n",
    "    if lat < -60:   return \"Antarctica\",  \"Antarctica\"\n",
    "    if 10.0 <= lat <= 20.0 and -85.0 <= lon <= -60.0:    return \"Caribbean\",     \"Caribbean Sea\"\n",
    "    if -10.0 <= lat <= 10.0 and 95.0 <= lon <= 141.0:    return \"Southeast Asia\",\"Indonesia\"\n",
    "    return \"Other\", \"Unknown\"\n",
    "\n",
    "# 5. Build the new locations list\n",
    "locs = []\n",
    "for row in raw_loc.itertuples(index=False):\n",
    "    lat, lon = row.latitude, row.longitude\n",
    "    if pd.isnull(lat) or pd.isnull(lon):\n",
    "        region, country = \"Other\", \"Unknown\"\n",
    "    else:\n",
    "        region, country = approx_region_country(lat, lon)\n",
    "    locs.append({\n",
    "        \"location_id\": row.meteorite_id,\n",
    "        \"latitude\":    lat,\n",
    "        \"longitude\":   lon,\n",
    "        \"region\":      region,\n",
    "        \"country\":     country\n",
    "    })\n",
    "\n",
    "# 6. Write it out\n",
    "pd.DataFrame(locs).to_csv(\"locations.csv\", index=False)\n",
    "print(f\"Regenerated locations.csv with {len(locs)} rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7536e666-0b19-4e7c-b9b6-e656060f4a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rewrote scientists.csv with columns: ['scientist_id', 'email', 'institution_id', 'scientist_name']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Read your original scientists file\n",
    "df = pd.read_csv(\"scientists.csv\")\n",
    "\n",
    "# 2. Reorder the columns to match your PG table:\n",
    "#    scientist_id | email | institution_id | scientist_name\n",
    "df = df[[\"scientist_id\", \"email\", \"institution_id\", \"scientist_name\"]]\n",
    "\n",
    "# 3. Overwrite the original scientists.csv with the fixed ordering\n",
    "df.to_csv(\"scientists.csv\", index=False)\n",
    "\n",
    "print(\"Rewrote scientists.csv with columns:\", list(df.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c43dd556-57fc-4969-86a0-125b3d0116b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote meteorites.csv with columns: ['meteorite_id', 'class_id', 'location_id', 'meteorite_name', 'mass', 'fall_type', 'fall_year']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Read your cleaned “landing” CSV\n",
    "df = pd.read_csv(\"cleaned_meteorite_landings.csv\")\n",
    "\n",
    "# 2. Select—and in this exact order—the columns your PG table expects:\n",
    "#    meteorite_id | class_id | location_id | meteorite_name | mass | fall_type | fall_year\n",
    "df_fixed = df[\n",
    "    [\n",
    "        \"meteorite_id\",\n",
    "        \"class_id\",\n",
    "        \"location_id\",\n",
    "        \"meteorite_name\",\n",
    "        \"mass\",\n",
    "        \"fall_type\",\n",
    "        \"fall_year\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "# 3. Write it out, overwriting your import‐source (or to a new file):\n",
    "df_fixed.to_csv(\"meteorites.csv\", index=False)\n",
    "\n",
    "print(\"Wrote meteorites.csv with columns:\", list(df_fixed.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd1384d6-92f2-4793-8d1c-c111e3f75a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "research_papers.csv rewritten with columns: ['paper_id', 'scientist_id', 'title', 'journal_name', 'publication_date']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Load the CSV you just exported\n",
    "df = pd.read_csv(\"research_papers.csv\")\n",
    "\n",
    "# 2. Re‐order to match the exact column order in your PG table:\n",
    "df = df[[\n",
    "    \"paper_id\",\n",
    "    \"scientist_id\",\n",
    "    \"title\",\n",
    "    \"journal_name\",\n",
    "    \"publication_date\",\n",
    "]]\n",
    "\n",
    "# 3. Overwrite the CSV so that pgAdmin will import it correctly\n",
    "df.to_csv(\"research_papers.csv\", index=False)\n",
    "\n",
    "print(\"research_papers.csv rewritten with columns:\", list(df.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5b5929-5924-49d7-8804-2f620682becc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
